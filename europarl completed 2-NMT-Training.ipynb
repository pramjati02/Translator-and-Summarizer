{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/ymoslem/OpenNMT-Tutorial/blob/main/2-NMT-Training.ipynb","timestamp":1697018617667}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"id":"vSUyCs23M_H2","executionInfo":{"status":"ok","timestamp":1697009644865,"user_tz":-120,"elapsed":17217,"user":{"displayName":"","userId":""}},"outputId":"b68c915b-7b5e-4e9d-905c-4a3b6c57303c","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Install OpenNMT-py 3.x\n","!pip3 install OpenNMT-py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting OpenNMT-py\n","  Downloading OpenNMT_py-3.4.1-py3-none-any.whl (252 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/252.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.2/252.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch<2.1,>=2.0 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.0.1+cu118)\n","Collecting configargparse (from OpenNMT-py)\n","  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n","Collecting ctranslate2<4,>=3.2 (from OpenNMT-py)\n","  Downloading ctranslate2-3.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.13.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n","Collecting waitress (from OpenNMT-py)\n","  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n","  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n","Collecting sacrebleu (from OpenNMT-py)\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n","  Downloading rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyahocorasick (from OpenNMT-py)\n","  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n","  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.6.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.2->OpenNMT-py) (1.23.5)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.59.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.4.4)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->OpenNMT-py) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->OpenNMT-py) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->OpenNMT-py) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->OpenNMT-py) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->OpenNMT-py) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->OpenNMT-py) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0->OpenNMT-py) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0->OpenNMT-py) (17.0.2)\n","Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n","  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n","Collecting portalocker (from sacrebleu->OpenNMT-py)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n","Collecting colorama (from sacrebleu->OpenNMT-py)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.10.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.10.13)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0->OpenNMT-py) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0->OpenNMT-py) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n","Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, OpenNMT-py\n","Successfully installed OpenNMT-py-3.4.1 colorama-0.4.6 configargparse-1.7 ctranslate2-3.20.0 fasttext-wheel-0.9.2 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.4.0 sacrebleu-2.3.1 waitress-2.1.2\n"]}]},{"cell_type":"markdown","source":["# Prepare Your Datasets\n","Please make sure you have completed the [first exercise](https://colab.research.google.com/drive/1rsFPnAQu9-_A6e2Aw9JYK3C8mXx9djsF?usp=sharing)."],"metadata":{"id":"vhgIdJn-cLqu"}},{"cell_type":"code","metadata":{"id":"dWVOWYedzZ_G","executionInfo":{"status":"ok","timestamp":1697010138314,"user_tz":-120,"elapsed":8,"user":{"displayName":"","userId":""}},"outputId":"8fd05bc2-f875-47ba-99b1-c15990473787","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Open the folder where you saved your prepapred datasets from the first exercise\n","# You might need to mount your Google Drive first\n","%cd /content/drive/MyDrive/nmt/\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/nmt\n","drive-download-20231011T073737Z-001.zip\n","Europarl.en-nl.en-filtered.en.subword.dev\n","Europarl.en-nl.en-filtered.en.subword.test\n","Europarl.en-nl.en-filtered.en.subword.train\n","Europarl.en-nl.nl-filtered.nl.subword.dev\n","Europarl.en-nl.nl-filtered.nl.subword.test\n","Europarl.en-nl.nl-filtered.nl.subword.train\n","source.model\n","source.vocab\n","target.model\n","target.vocab\n"]}]},{"cell_type":"code","source":["!unzip /content/drive/MyDrive/nmt/drive-download-20231011T073737Z-001.zip"],"metadata":{"id":"MBEWZiKmrjzm","executionInfo":{"status":"ok","timestamp":1697010078696,"user_tz":-120,"elapsed":17608,"user":{"displayName":"","userId":""}},"outputId":"770bef0c-56ce-44ab-ac6e-77158c74ca51","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/nmt/drive-download-20231011T073737Z-001.zip\n","  inflating: source.model            \n","  inflating: Europarl.en-nl.nl-filtered.nl.subword.test  \n","  inflating: source.vocab            \n","  inflating: target.model            \n","  inflating: Europarl.en-nl.en-filtered.en.subword.test  \n","  inflating: Europarl.en-nl.en-filtered.en.subword.dev  \n","  inflating: Europarl.en-nl.nl-filtered.nl.subword.dev  \n","  inflating: target.vocab            \n","  inflating: Europarl.en-nl.nl-filtered.nl.subword.train  \n","  inflating: Europarl.en-nl.en-filtered.en.subword.train  \n"]}]},{"cell_type":"markdown","metadata":{"id":"MPlmhd426B7l"},"source":["# Create the Training Configuration File\n","\n","The following config file matches most of the recommended values for the Transformer model [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762). As the current dataset is small, we reduced the following values:\n","* `train_steps` - for datasets with a few millions of sentences, consider using a value between 100000 and 200000, or more! Enabling the option `early_stopping` can help stop the training when there is no considerable improvement.\n","* `valid_steps` - 10000 can be good if the value `train_steps` is big enough.\n","* `warmup_steps` - obviously, its value must be less than `train_steps`. Try 4000 and 8000 values.\n","\n","Refer to [OpenNMT-py training parameters](https://opennmt.net/OpenNMT-py/options/train.html) for more details. If you are interested in further explanation of the Transformer model, you can check this article, [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)."]},{"cell_type":"code","metadata":{"id":"qbW7Xek6UDlY"},"source":["# Create the YAML configuration file\n","# On a regular machine, you can create it manually or with nano\n","# Note here we are using some smaller values because the dataset is small\n","# For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint\n","\n","config = '''# config.yaml\n","\n","\n","## Where the samples will be written\n","save_data: run\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: Europarl.en-nl.en-filtered.en.subword.train\n","        path_tgt: Europarl.en-nl.nl-filtered.nl.subword.train\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: Europarl.en-nl.en-filtered.en.subword.dev\n","        path_tgt: Europarl.en-nl.nl-filtered.nl.subword.dev\n","        transforms: [filtertoolong]\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: run/source.vocab\n","tgt_vocab: run/target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: 50000\n","tgt_vocab_size: 50000\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: source.model\n","tgt_subword_model: target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: train.log\n","save_model: models/model.en-nl\n","\n","# Stop training if it does not imporve after n validations\n","early_stopping: 4\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: 1000\n","\n","# To save space, limit checkpoints to last n\n","# keep_checkpoint: 3\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps\n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: 10000\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: 1000\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: 1000\n","report_every: 100\n","\n","# Number of GPUs, and IDs of GPUs\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Batching\n","bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 2048\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 2\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 6\n","dec_layers: 6\n","heads: 8\n","hidden_size: 512\n","word_vec_size: 512\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.2]\n","attention_dropout: [0.1]\n","'''\n","\n","with open(\"config.yaml\", \"w+\") as config_yaml:\n","  config_yaml.write(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4Bvr2lIGpxEb","executionInfo":{"status":"ok","timestamp":1697009606206,"user_tz":-120,"elapsed":29600,"user":{"displayName":"","userId":""}},"outputId":"3d0491db-8873-4e54-c96f-df6b5fc96b63","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"vsL4zycvLMUx"},"source":["# [Optional] Check the content of the configuration file\n","!cat config.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F0bcqYkEXhRY"},"source":["# Build Vocabulary\n","\n","For large datasets, it is not feasable to use all words/tokens found in the corpus. Instead, a specific set of vocabulary is extracted from the training dataset, usually betweeen 32k and 100k words. This is the main purpose of the vocabulary building step."]},{"cell_type":"code","metadata":{"id":"AuwltKp_VhnQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d9d5e5e-df7b-474b-b281-369424c47603"},"source":["# Find the number of CPUs/cores on the machine\n","!nproc --all"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"code","metadata":{"id":"P2GV1PgyUsJr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"54a8fd49-270e-4428-f093-26e533c5f40a","executionInfo":{"status":"ok","timestamp":1697010449286,"user_tz":-120,"elapsed":194827,"user":{"displayName":"","userId":""}}},"source":["# Build Vocabulary\n","\n","# -config: path to your config.yaml file\n","# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n","# -num_threads: change it to match the number of CPUs to run it faster\n","\n","!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 07:44:18.362361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-11 07:44:19.412991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-10-11 07:44:21.493838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-11 07:44:21.494435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-11 07:44:21.494643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-10-11 07:44:22,822 INFO] Counter vocab from -1 samples.\n","[2023-10-11 07:44:22,822 INFO] n_sample=-1: Build vocab on full datasets.\n","[2023-10-11 07:47:24,187 INFO] * Transform statistics for corpus_1(50.00%):\n","\t\t\t* FilterTooLongStats(filtered=10186)\n","\n","[2023-10-11 07:47:24,398 INFO] * Transform statistics for corpus_1(50.00%):\n","\t\t\t* FilterTooLongStats(filtered=10206)\n","\n","[2023-10-11 07:47:24,456 INFO] Counters src: 12575\n","[2023-10-11 07:47:24,456 INFO] Counters tgt: 24873\n"]}]},{"cell_type":"markdown","metadata":{"id":"ncWyNtxiO_Ov"},"source":["From the **Runtime menu** > **Change runtime type**, make sure that the \"**Hardware accelerator**\" is \"**GPU**\".\n"]},{"cell_type":"code","metadata":{"id":"TMMPeS-pSV8I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea51133a-beaa-4642-e8ba-7bd9159ada68"},"source":["# Check if the GPU is active\n","!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-1759f39f-df0c-a03f-3066-463f5fec7c38)\n"]}]},{"cell_type":"code","metadata":{"id":"_3rVQhd4NXNG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"181eb6a3-cc09-45b6-de4e-b1e88e45f97b"},"source":["# Check if the GPU is visable to PyTorch\n","\n","import torch\n","\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))\n","\n","gpu_memory = torch.cuda.mem_get_info(0)\n","print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla T4\n","Free GPU memory: 15007.75 out of: 15109.75\n"]}]},{"cell_type":"markdown","metadata":{"id":"8aCxETSnXcL-"},"source":["# Training\n","\n","Now, start training your NMT model! ğŸ‰ ğŸ‰ ğŸ‰"]},{"cell_type":"code","source":["!rm -rf drive/MyDrive/nmt/models/"],"metadata":{"id":"HZd1o1kIb6Nv"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"prJCKA2CP-dl","executionInfo":{"status":"ok","timestamp":1697017784161,"user_tz":-120,"elapsed":7226968,"user":{"displayName":"","userId":""}},"outputId":"42c322b5-99bc-4574-dbb8-4d5c65f436b2","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Train the NMT model\n","!onmt_train -config config.yaml"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 07:49:17.604071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-11 07:49:18.690403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-10-11 07:49:20.115497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-11 07:49:20.115959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-11 07:49:20.116160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","[2023-10-11 07:49:20,847 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-10-11 07:49:20,848 INFO] Parsed 2 corpora from -data.\n","[2023-10-11 07:49:20,849 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-10-11 07:49:20,977 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'â–', 'â–the', 's', ',', 'e', '.']\n","[2023-10-11 07:49:20,978 INFO] The decoder start token is: <s>\n","[2023-10-11 07:49:20,978 INFO] Building model...\n","[2023-10-11 07:49:22,039 INFO] Switching model to float32 for amp/apex_amp\n","[2023-10-11 07:49:22,039 INFO] Non quantized layer compute is fp16\n","[2023-10-11 07:49:30,417 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(12584, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-5): 6 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(24880, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-5): 6 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=512, out_features=24880, bias=True)\n",")\n","[2023-10-11 07:49:30,421 INFO] encoder: 25330688\n","[2023-10-11 07:49:30,421 INFO] decoder: 50687280\n","[2023-10-11 07:49:30,421 INFO] * number of parameters: 76017968\n","[2023-10-11 07:49:30,422 INFO] Trainable parameters = {'torch.float32': 76017968, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-10-11 07:49:30,422 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-10-11 07:49:30,422 INFO]  * src vocab size = 12584\n","[2023-10-11 07:49:30,422 INFO]  * tgt vocab size = 24880\n","[2023-10-11 07:49:30,428 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-10-11 07:49:30,429 INFO] Starting training on GPU: [0]\n","[2023-10-11 07:49:30,429 INFO] Start training loop and validate every 1000 steps...\n","[2023-10-11 07:49:30,429 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-10-11 07:51:18,034 INFO] Step 100/10000; acc: 8.2; ppl: 2463.7; xent: 7.8; lr: 0.00028; sents:   23248; bsz: 2728/3894/58; 10142/14476 tok/s;    108 sec;\n","[2023-10-11 07:52:18,654 INFO] Step 200/10000; acc: 25.1; ppl: 170.7; xent: 5.1; lr: 0.00056; sents:   22899; bsz: 2767/3921/57; 18259/25876 tok/s;    168 sec;\n","[2023-10-11 07:53:19,966 INFO] Step 300/10000; acc: 36.7; ppl:  62.2; xent: 4.1; lr: 0.00084; sents:   21905; bsz: 2772/3905/55; 18085/25473 tok/s;    230 sec;\n","[2023-10-11 07:54:20,847 INFO] Step 400/10000; acc: 43.1; ppl:  43.3; xent: 3.8; lr: 0.00112; sents:   24363; bsz: 2751/3907/61; 18072/25669 tok/s;    290 sec;\n","[2023-10-11 07:55:21,461 INFO] Step 500/10000; acc: 46.7; ppl:  35.5; xent: 3.6; lr: 0.00140; sents:   23091; bsz: 2704/3891/58; 17847/25680 tok/s;    351 sec;\n","[2023-10-11 07:56:22,435 INFO] Step 600/10000; acc: 48.9; ppl:  31.8; xent: 3.5; lr: 0.00168; sents:   24072; bsz: 2740/3873/60; 17978/25405 tok/s;    412 sec;\n","[2023-10-11 07:57:23,358 INFO] Step 700/10000; acc: 50.8; ppl:  28.9; xent: 3.4; lr: 0.00196; sents:   24936; bsz: 2753/3866/62; 18075/25383 tok/s;    473 sec;\n","[2023-10-11 07:58:24,620 INFO] Step 800/10000; acc: 51.8; ppl:  27.6; xent: 3.3; lr: 0.00224; sents:   24040; bsz: 2769/3877/60; 18080/25312 tok/s;    534 sec;\n","[2023-10-11 07:59:25,565 INFO] Step 900/10000; acc: 52.5; ppl:  26.6; xent: 3.3; lr: 0.00252; sents:   23292; bsz: 2739/3876/58; 17980/25440 tok/s;    595 sec;\n","[2023-10-11 08:00:26,309 INFO] Step 1000/10000; acc: 53.2; ppl:  25.5; xent: 3.2; lr: 0.00279; sents:   23380; bsz: 2716/3907/58; 17885/25727 tok/s;    656 sec;\n","[2023-10-11 08:00:30,771 INFO] valid stats calculation\n","                           took: 4.460196256637573 s.\n","[2023-10-11 08:00:30,772 INFO] Train perplexity: 60.9258\n","[2023-10-11 08:00:30,772 INFO] Train accuracy: 41.6714\n","[2023-10-11 08:00:30,772 INFO] Sentences processed: 235226\n","[2023-10-11 08:00:30,772 INFO] Average bsz: 2744/3892/59\n","[2023-10-11 08:00:30,772 INFO] Validation perplexity: 24.5511\n","[2023-10-11 08:00:30,773 INFO] Validation accuracy: 54.2932\n","[2023-10-11 08:00:30,773 INFO] Model is improving ppl: inf --> 24.5511.\n","[2023-10-11 08:00:30,773 INFO] Model is improving acc: -inf --> 54.2932.\n","[2023-10-11 08:00:30,779 INFO] Saving checkpoint models/model.en-nl_step_1000.pt\n","[2023-10-11 08:01:37,251 INFO] Step 1100/10000; acc: 53.3; ppl:  25.3; xent: 3.2; lr: 0.00266; sents:   22812; bsz: 2783/3920/57; 15693/22101 tok/s;    727 sec;\n","[2023-10-11 08:03:33,617 INFO] Step 1200/10000; acc: 54.6; ppl:  23.7; xent: 3.2; lr: 0.00255; sents:   24288; bsz: 2749/3912/61; 9449/13447 tok/s;    843 sec;\n","[2023-10-11 08:04:35,180 INFO] Step 1300/10000; acc: 55.1; ppl:  23.1; xent: 3.1; lr: 0.00245; sents:   23013; bsz: 2738/3895/58; 17792/25308 tok/s;    905 sec;\n","[2023-10-11 08:05:36,627 INFO] Step 1400/10000; acc: 55.9; ppl:  22.2; xent: 3.1; lr: 0.00236; sents:   23777; bsz: 2785/3917/59; 18129/25499 tok/s;    966 sec;\n","[2023-10-11 08:06:38,213 INFO] Step 1500/10000; acc: 56.6; ppl:  21.4; xent: 3.1; lr: 0.00228; sents:   23433; bsz: 2759/3911/59; 17917/25404 tok/s;   1028 sec;\n","[2023-10-11 08:07:39,806 INFO] Step 1600/10000; acc: 57.0; ppl:  21.0; xent: 3.0; lr: 0.00221; sents:   22866; bsz: 2725/3877/57; 17694/25181 tok/s;   1089 sec;\n","[2023-10-11 08:08:41,078 INFO] Step 1700/10000; acc: 57.6; ppl:  20.4; xent: 3.0; lr: 0.00214; sents:   24099; bsz: 2747/3880/60; 17936/25332 tok/s;   1151 sec;\n","[2023-10-11 08:09:42,329 INFO] Step 1800/10000; acc: 58.2; ppl:  19.9; xent: 3.0; lr: 0.00208; sents:   23614; bsz: 2736/3867/59; 17869/25254 tok/s;   1212 sec;\n","[2023-10-11 08:10:44,022 INFO] Step 1900/10000; acc: 58.3; ppl:  19.7; xent: 3.0; lr: 0.00203; sents:   23893; bsz: 2752/3881/60; 17846/25164 tok/s;   1274 sec;\n","[2023-10-11 08:11:45,584 INFO] Step 2000/10000; acc: 58.6; ppl:  19.4; xent: 3.0; lr: 0.00198; sents:   23070; bsz: 2747/3891/58; 17848/25280 tok/s;   1335 sec;\n","[2023-10-11 08:11:45,770 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 08:11:50,766 INFO] valid stats calculation\n","                           took: 5.179354667663574 s.\n","[2023-10-11 08:11:50,768 INFO] Train perplexity: 36.213\n","[2023-10-11 08:11:50,768 INFO] Train accuracy: 49.0966\n","[2023-10-11 08:11:50,768 INFO] Sentences processed: 470091\n","[2023-10-11 08:11:50,768 INFO] Average bsz: 2748/3893/59\n","[2023-10-11 08:11:50,768 INFO] Validation perplexity: 18.2546\n","[2023-10-11 08:11:50,768 INFO] Validation accuracy: 59.9775\n","[2023-10-11 08:11:50,768 INFO] Model is improving ppl: 24.5511 --> 18.2546.\n","[2023-10-11 08:11:50,768 INFO] Model is improving acc: 54.2932 --> 59.9775.\n","[2023-10-11 08:11:50,775 INFO] Saving checkpoint models/model.en-nl_step_2000.pt\n","[2023-10-11 08:12:57,668 INFO] Step 2100/10000; acc: 59.0; ppl:  19.1; xent: 2.9; lr: 0.00193; sents:   22692; bsz: 2758/3900/57; 15302/21641 tok/s;   1407 sec;\n","[2023-10-11 08:13:59,269 INFO] Step 2200/10000; acc: 59.5; ppl:  18.6; xent: 2.9; lr: 0.00188; sents:   23612; bsz: 2753/3909/59; 17875/25382 tok/s;   1469 sec;\n","[2023-10-11 08:15:56,984 INFO] Step 2300/10000; acc: 60.0; ppl:  18.2; xent: 2.9; lr: 0.00184; sents:   24494; bsz: 2735/3892/61; 9294/13226 tok/s;   1587 sec;\n","[2023-10-11 08:16:58,390 INFO] Step 2400/10000; acc: 59.9; ppl:  18.2; xent: 2.9; lr: 0.00180; sents:   22618; bsz: 2754/3890/57; 17941/25337 tok/s;   1648 sec;\n","[2023-10-11 08:17:59,956 INFO] Step 2500/10000; acc: 60.4; ppl:  17.8; xent: 2.9; lr: 0.00177; sents:   24423; bsz: 2772/3894/61; 18008/25300 tok/s;   1710 sec;\n","[2023-10-11 08:19:01,475 INFO] Step 2600/10000; acc: 60.6; ppl:  17.7; xent: 2.9; lr: 0.00173; sents:   23971; bsz: 2732/3880/60; 17765/25226 tok/s;   1771 sec;\n","[2023-10-11 08:20:03,020 INFO] Step 2700/10000; acc: 60.7; ppl:  17.5; xent: 2.9; lr: 0.00170; sents:   23046; bsz: 2751/3907/58; 17878/25392 tok/s;   1833 sec;\n","[2023-10-11 08:21:04,436 INFO] Step 2800/10000; acc: 61.0; ppl:  17.4; xent: 2.9; lr: 0.00167; sents:   23125; bsz: 2754/3887/58; 17937/25316 tok/s;   1894 sec;\n","[2023-10-11 08:22:06,168 INFO] Step 2900/10000; acc: 61.1; ppl:  17.2; xent: 2.8; lr: 0.00164; sents:   22301; bsz: 2770/3897/56; 17948/25249 tok/s;   1956 sec;\n","[2023-10-11 08:23:07,432 INFO] Step 3000/10000; acc: 61.8; ppl:  16.7; xent: 2.8; lr: 0.00161; sents:   23960; bsz: 2747/3914/60; 17938/25552 tok/s;   2017 sec;\n","[2023-10-11 08:23:07,625 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 08:23:12,361 INFO] valid stats calculation\n","                           took: 4.9274585247039795 s.\n","[2023-10-11 08:23:12,365 INFO] Train perplexity: 28.5879\n","[2023-10-11 08:23:12,365 INFO] Train accuracy: 52.866\n","[2023-10-11 08:23:12,365 INFO] Sentences processed: 704333\n","[2023-10-11 08:23:12,365 INFO] Average bsz: 2750/3895/59\n","[2023-10-11 08:23:12,365 INFO] Validation perplexity: 15.9247\n","[2023-10-11 08:23:12,365 INFO] Validation accuracy: 62.9434\n","[2023-10-11 08:23:12,365 INFO] Model is improving ppl: 18.2546 --> 15.9247.\n","[2023-10-11 08:23:12,365 INFO] Model is improving acc: 59.9775 --> 62.9434.\n","[2023-10-11 08:23:12,378 INFO] Saving checkpoint models/model.en-nl_step_3000.pt\n","[2023-10-11 08:24:38,280 INFO] Step 3100/10000; acc: 61.8; ppl:  16.7; xent: 2.8; lr: 0.00159; sents:   23773; bsz: 2757/3889/59; 12139/17125 tok/s;   2108 sec;\n","[2023-10-11 08:25:39,780 INFO] Step 3200/10000; acc: 62.0; ppl:  16.5; xent: 2.8; lr: 0.00156; sents:   24402; bsz: 2796/3900/61; 18187/25367 tok/s;   2169 sec;\n","[2023-10-11 08:26:41,242 INFO] Step 3300/10000; acc: 62.5; ppl:  16.2; xent: 2.8; lr: 0.00154; sents:   22868; bsz: 2727/3919/57; 17745/25504 tok/s;   2231 sec;\n","[2023-10-11 08:28:44,064 INFO] Step 3400/10000; acc: 62.7; ppl:  16.0; xent: 2.8; lr: 0.00152; sents:   24270; bsz: 2728/3917/61; 8884/12758 tok/s;   2354 sec;\n","[2023-10-11 08:29:45,461 INFO] Step 3500/10000; acc: 62.6; ppl:  16.1; xent: 2.8; lr: 0.00149; sents:   23432; bsz: 2748/3879/59; 17905/25270 tok/s;   2415 sec;\n","[2023-10-11 08:30:47,249 INFO] Step 3600/10000; acc: 63.0; ppl:  15.8; xent: 2.8; lr: 0.00147; sents:   23031; bsz: 2730/3912/58; 17675/25326 tok/s;   2477 sec;\n","[2023-10-11 08:31:48,881 INFO] Step 3700/10000; acc: 62.8; ppl:  15.9; xent: 2.8; lr: 0.00145; sents:   22186; bsz: 2737/3871/55; 17764/25125 tok/s;   2538 sec;\n","[2023-10-11 08:32:50,711 INFO] Step 3800/10000; acc: 63.1; ppl:  15.7; xent: 2.8; lr: 0.00143; sents:   23540; bsz: 2774/3911/59; 17943/25301 tok/s;   2600 sec;\n","[2023-10-11 08:33:52,527 INFO] Step 3900/10000; acc: 63.3; ppl:  15.6; xent: 2.7; lr: 0.00142; sents:   23707; bsz: 2760/3868/59; 17858/25032 tok/s;   2662 sec;\n","[2023-10-11 08:34:54,080 INFO] Step 4000/10000; acc: 63.5; ppl:  15.4; xent: 2.7; lr: 0.00140; sents:   23106; bsz: 2707/3875/58; 17590/25182 tok/s;   2724 sec;\n","[2023-10-11 08:34:54,253 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 08:34:58,693 INFO] valid stats calculation\n","                           took: 4.610924005508423 s.\n","[2023-10-11 08:34:58,695 INFO] Train perplexity: 24.7189\n","[2023-10-11 08:34:58,696 INFO] Train accuracy: 55.3329\n","[2023-10-11 08:34:58,696 INFO] Sentences processed: 938648\n","[2023-10-11 08:34:58,696 INFO] Average bsz: 2749/3894/59\n","[2023-10-11 08:34:58,696 INFO] Validation perplexity: 14.6561\n","[2023-10-11 08:34:58,696 INFO] Validation accuracy: 64.7122\n","[2023-10-11 08:34:58,696 INFO] Model is improving ppl: 15.9247 --> 14.6561.\n","[2023-10-11 08:34:58,696 INFO] Model is improving acc: 62.9434 --> 64.7122.\n","[2023-10-11 08:34:58,703 INFO] Saving checkpoint models/model.en-nl_step_4000.pt\n","[2023-10-11 08:36:24,477 INFO] Step 4100/10000; acc: 63.5; ppl:  15.4; xent: 2.7; lr: 0.00138; sents:   22792; bsz: 2778/3901/57; 12294/17261 tok/s;   2814 sec;\n","[2023-10-11 08:37:26,041 INFO] Step 4200/10000; acc: 64.1; ppl:  15.1; xent: 2.7; lr: 0.00136; sents:   23275; bsz: 2722/3898/58; 17686/25328 tok/s;   2876 sec;\n","[2023-10-11 08:38:27,700 INFO] Step 4300/10000; acc: 64.2; ppl:  15.0; xent: 2.7; lr: 0.00135; sents:   24454; bsz: 2755/3872/61; 17872/25116 tok/s;   2937 sec;\n","[2023-10-11 08:39:29,501 INFO] Step 4400/10000; acc: 64.3; ppl:  14.9; xent: 2.7; lr: 0.00133; sents:   23602; bsz: 2749/3909/59; 17796/25304 tok/s;   2999 sec;\n","[2023-10-11 08:41:28,370 INFO] Step 4500/10000; acc: 64.2; ppl:  15.0; xent: 2.7; lr: 0.00132; sents:   24341; bsz: 2811/3894/61; 9460/13105 tok/s;   3118 sec;\n","[2023-10-11 08:42:29,571 INFO] Step 4600/10000; acc: 64.9; ppl:  14.5; xent: 2.7; lr: 0.00130; sents:   25202; bsz: 2724/3873/63; 17807/25316 tok/s;   3179 sec;\n","[2023-10-11 08:43:31,281 INFO] Step 4700/10000; acc: 64.6; ppl:  14.7; xent: 2.7; lr: 0.00129; sents:   23419; bsz: 2768/3907/59; 17942/25326 tok/s;   3241 sec;\n","[2023-10-11 08:44:32,694 INFO] Step 4800/10000; acc: 64.9; ppl:  14.4; xent: 2.7; lr: 0.00128; sents:   23761; bsz: 2719/3870/59; 17707/25205 tok/s;   3302 sec;\n","[2023-10-11 08:45:33,986 INFO] Step 4900/10000; acc: 65.0; ppl:  14.4; xent: 2.7; lr: 0.00126; sents:   23207; bsz: 2739/3909/58; 17878/25509 tok/s;   3364 sec;\n","[2023-10-11 08:46:35,454 INFO] Step 5000/10000; acc: 65.3; ppl:  14.2; xent: 2.7; lr: 0.00125; sents:   23535; bsz: 2720/3887/59; 17701/25298 tok/s;   3425 sec;\n","[2023-10-11 08:46:35,722 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 08:46:40,634 INFO] valid stats calculation\n","                           took: 5.177242755889893 s.\n","[2023-10-11 08:46:40,637 INFO] Train perplexity: 22.2979\n","[2023-10-11 08:46:40,637 INFO] Train accuracy: 57.1654\n","[2023-10-11 08:46:40,637 INFO] Sentences processed: 1.17624e+06\n","[2023-10-11 08:46:40,637 INFO] Average bsz: 2749/3894/59\n","[2023-10-11 08:46:40,637 INFO] Validation perplexity: 13.6212\n","[2023-10-11 08:46:40,637 INFO] Validation accuracy: 66.4589\n","[2023-10-11 08:46:40,637 INFO] Model is improving ppl: 14.6561 --> 13.6212.\n","[2023-10-11 08:46:40,637 INFO] Model is improving acc: 64.7122 --> 66.4589.\n","[2023-10-11 08:46:40,644 INFO] Saving checkpoint models/model.en-nl_step_5000.pt\n","[2023-10-11 08:48:19,206 INFO] Step 5100/10000; acc: 65.0; ppl:  14.4; xent: 2.7; lr: 0.00124; sents:   22015; bsz: 2755/3893/55; 10623/15010 tok/s;   3529 sec;\n","[2023-10-11 08:49:20,596 INFO] Step 5200/10000; acc: 65.4; ppl:  14.1; xent: 2.6; lr: 0.00123; sents:   23367; bsz: 2735/3877/58; 17823/25263 tok/s;   3590 sec;\n","[2023-10-11 08:50:21,945 INFO] Step 5300/10000; acc: 65.6; ppl:  14.1; xent: 2.6; lr: 0.00121; sents:   23790; bsz: 2754/3897/59; 17956/25412 tok/s;   3652 sec;\n","[2023-10-11 08:51:23,467 INFO] Step 5400/10000; acc: 65.6; ppl:  14.0; xent: 2.6; lr: 0.00120; sents:   22955; bsz: 2723/3899/57; 17703/25351 tok/s;   3713 sec;\n","[2023-10-11 08:52:25,329 INFO] Step 5500/10000; acc: 65.6; ppl:  14.0; xent: 2.6; lr: 0.00119; sents:   22540; bsz: 2773/3908/56; 17933/25270 tok/s;   3775 sec;\n","[2023-10-11 08:54:30,583 INFO] Step 5600/10000; acc: 66.0; ppl:  13.8; xent: 2.6; lr: 0.00118; sents:   23744; bsz: 2719/3917/59; 8683/12508 tok/s;   3900 sec;\n","[2023-10-11 08:55:32,393 INFO] Step 5700/10000; acc: 65.9; ppl:  13.8; xent: 2.6; lr: 0.00117; sents:   23201; bsz: 2776/3888/58; 17967/25161 tok/s;   3962 sec;\n","[2023-10-11 08:56:34,227 INFO] Step 5800/10000; acc: 66.2; ppl:  13.7; xent: 2.6; lr: 0.00116; sents:   23844; bsz: 2780/3897/60; 17984/25211 tok/s;   4024 sec;\n","[2023-10-11 08:57:35,921 INFO] Step 5900/10000; acc: 66.3; ppl:  13.6; xent: 2.6; lr: 0.00115; sents:   23504; bsz: 2739/3884/59; 17762/25183 tok/s;   4085 sec;\n","[2023-10-11 08:58:37,711 INFO] Step 6000/10000; acc: 66.5; ppl:  13.5; xent: 2.6; lr: 0.00114; sents:   23873; bsz: 2766/3907/60; 17909/25291 tok/s;   4147 sec;\n","[2023-10-11 08:58:38,059 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 08:58:42,998 INFO] valid stats calculation\n","                           took: 5.283465147018433 s.\n","[2023-10-11 08:58:43,000 INFO] Train perplexity: 20.6083\n","[2023-10-11 08:58:43,000 INFO] Train accuracy: 58.6081\n","[2023-10-11 08:58:43,000 INFO] Sentences processed: 1.40907e+06\n","[2023-10-11 08:58:43,000 INFO] Average bsz: 2749/3894/59\n","[2023-10-11 08:58:43,000 INFO] Validation perplexity: 12.8117\n","[2023-10-11 08:58:43,000 INFO] Validation accuracy: 67.7806\n","[2023-10-11 08:58:43,000 INFO] Model is improving ppl: 13.6212 --> 12.8117.\n","[2023-10-11 08:58:43,000 INFO] Model is improving acc: 66.4589 --> 67.7806.\n","[2023-10-11 08:58:43,007 INFO] Saving checkpoint models/model.en-nl_step_6000.pt\n","[2023-10-11 09:00:27,348 INFO] Step 6100/10000; acc: 66.8; ppl:  13.3; xent: 2.6; lr: 0.00113; sents:   23242; bsz: 2709/3863/58; 9882/14092 tok/s;   4257 sec;\n","[2023-10-11 09:01:29,339 INFO] Step 6200/10000; acc: 67.0; ppl:  13.2; xent: 2.6; lr: 0.00112; sents:   23942; bsz: 2743/3908/60; 17700/25215 tok/s;   4319 sec;\n","[2023-10-11 09:02:31,467 INFO] Step 6300/10000; acc: 66.8; ppl:  13.4; xent: 2.6; lr: 0.00111; sents:   23312; bsz: 2784/3882/58; 17924/24994 tok/s;   4381 sec;\n","[2023-10-11 09:03:33,645 INFO] Step 6400/10000; acc: 67.1; ppl:  13.2; xent: 2.6; lr: 0.00110; sents:   23813; bsz: 2765/3884/60; 17789/24989 tok/s;   4443 sec;\n","[2023-10-11 09:04:35,492 INFO] Step 6500/10000; acc: 67.3; ppl:  13.0; xent: 2.6; lr: 0.00110; sents:   23320; bsz: 2719/3907/58; 17583/25268 tok/s;   4505 sec;\n","[2023-10-11 09:05:37,177 INFO] Step 6600/10000; acc: 67.5; ppl:  12.9; xent: 2.6; lr: 0.00109; sents:   22778; bsz: 2719/3877/57; 17630/25140 tok/s;   4567 sec;\n","[2023-10-11 09:07:38,995 INFO] Step 6700/10000; acc: 67.6; ppl:  12.9; xent: 2.6; lr: 0.00108; sents:   23008; bsz: 2742/3898/58; 9003/12798 tok/s;   4689 sec;\n","[2023-10-11 09:08:40,705 INFO] Step 6800/10000; acc: 67.8; ppl:  12.8; xent: 2.5; lr: 0.00107; sents:   23817; bsz: 2750/3907/60; 17828/25324 tok/s;   4750 sec;\n","[2023-10-11 09:09:42,487 INFO] Step 6900/10000; acc: 67.8; ppl:  12.8; xent: 2.5; lr: 0.00106; sents:   23228; bsz: 2745/3901/58; 17770/25260 tok/s;   4812 sec;\n","[2023-10-11 09:10:44,496 INFO] Step 7000/10000; acc: 67.7; ppl:  12.8; xent: 2.6; lr: 0.00106; sents:   23030; bsz: 2752/3886/58; 17750/25071 tok/s;   4874 sec;\n","[2023-10-11 09:10:44,667 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 09:10:49,128 INFO] valid stats calculation\n","                           took: 4.6300506591796875 s.\n","[2023-10-11 09:10:49,130 INFO] Train perplexity: 19.3019\n","[2023-10-11 09:10:49,131 INFO] Train accuracy: 59.8548\n","[2023-10-11 09:10:49,131 INFO] Sentences processed: 1.64256e+06\n","[2023-10-11 09:10:49,131 INFO] Average bsz: 2748/3894/59\n","[2023-10-11 09:10:49,131 INFO] Validation perplexity: 12.0211\n","[2023-10-11 09:10:49,131 INFO] Validation accuracy: 69.2806\n","[2023-10-11 09:10:49,131 INFO] Model is improving ppl: 12.8117 --> 12.0211.\n","[2023-10-11 09:10:49,131 INFO] Model is improving acc: 67.7806 --> 69.2806.\n","[2023-10-11 09:10:49,138 INFO] Saving checkpoint models/model.en-nl_step_7000.pt\n","[2023-10-11 09:12:56,997 INFO] Step 7100/10000; acc: 68.2; ppl:  12.6; xent: 2.5; lr: 0.00105; sents:   23036; bsz: 2722/3888/58; 8217/11738 tok/s;   5007 sec;\n","[2023-10-11 09:13:58,396 INFO] Step 7200/10000; acc: 68.3; ppl:  12.5; xent: 2.5; lr: 0.00104; sents:   24137; bsz: 2757/3898/60; 17962/25398 tok/s;   5068 sec;\n","[2023-10-11 09:15:00,277 INFO] Step 7300/10000; acc: 68.3; ppl:  12.5; xent: 2.5; lr: 0.00103; sents:   23698; bsz: 2745/3885/59; 17741/25114 tok/s;   5130 sec;\n","[2023-10-11 09:16:02,062 INFO] Step 7400/10000; acc: 68.6; ppl:  12.4; xent: 2.5; lr: 0.00103; sents:   24341; bsz: 2741/3901/61; 17745/25256 tok/s;   5192 sec;\n","[2023-10-11 09:17:03,768 INFO] Step 7500/10000; acc: 68.5; ppl:  12.4; xent: 2.5; lr: 0.00102; sents:   22892; bsz: 2729/3893/57; 17693/25235 tok/s;   5253 sec;\n","[2023-10-11 09:18:05,806 INFO] Step 7600/10000; acc: 68.7; ppl:  12.3; xent: 2.5; lr: 0.00101; sents:   23742; bsz: 2780/3905/59; 17925/25181 tok/s;   5315 sec;\n","[2023-10-11 09:19:07,395 INFO] Step 7700/10000; acc: 68.5; ppl:  12.4; xent: 2.5; lr: 0.00101; sents:   23502; bsz: 2762/3886/59; 17940/25236 tok/s;   5377 sec;\n","[2023-10-11 09:19:36,486 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=19137)\n","\n","[2023-10-11 09:19:36,487 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-10-11 09:21:02,778 INFO] Step 7800/10000; acc: 68.9; ppl:  12.2; xent: 2.5; lr: 0.00100; sents:   23375; bsz: 2761/3891/58; 9571/13488 tok/s;   5492 sec;\n","[2023-10-11 09:22:04,449 INFO] Step 7900/10000; acc: 69.2; ppl:  12.1; xent: 2.5; lr: 0.00099; sents:   24090; bsz: 2747/3887/60; 17817/25212 tok/s;   5554 sec;\n","[2023-10-11 09:23:06,231 INFO] Step 8000/10000; acc: 69.0; ppl:  12.1; xent: 2.5; lr: 0.00099; sents:   23508; bsz: 2781/3898/59; 18007/25239 tok/s;   5616 sec;\n","[2023-10-11 09:23:11,130 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 09:23:15,675 INFO] valid stats calculation\n","                           took: 9.440649032592773 s.\n","[2023-10-11 09:23:15,677 INFO] Train perplexity: 18.2517\n","[2023-10-11 09:23:15,677 INFO] Train accuracy: 60.9511\n","[2023-10-11 09:23:15,677 INFO] Sentences processed: 1.87888e+06\n","[2023-10-11 09:23:15,677 INFO] Average bsz: 2749/3894/59\n","[2023-10-11 09:23:15,677 INFO] Validation perplexity: 11.3902\n","[2023-10-11 09:23:15,677 INFO] Validation accuracy: 70.5202\n","[2023-10-11 09:23:15,677 INFO] Model is improving ppl: 12.0211 --> 11.3902.\n","[2023-10-11 09:23:15,677 INFO] Model is improving acc: 69.2806 --> 70.5202.\n","[2023-10-11 09:23:15,684 INFO] Saving checkpoint models/model.en-nl_step_8000.pt\n","[2023-10-11 09:25:24,568 INFO] Step 8100/10000; acc: 69.3; ppl:  12.0; xent: 2.5; lr: 0.00098; sents:   23306; bsz: 2705/3874/58; 7822/11201 tok/s;   5754 sec;\n","[2023-10-11 09:26:26,493 INFO] Step 8200/10000; acc: 69.5; ppl:  11.9; xent: 2.5; lr: 0.00098; sents:   24746; bsz: 2770/3903/62; 17894/25211 tok/s;   5816 sec;\n","[2023-10-11 09:27:28,110 INFO] Step 8300/10000; acc: 69.6; ppl:  11.8; xent: 2.5; lr: 0.00097; sents:   24226; bsz: 2695/3866/61; 17499/25098 tok/s;   5878 sec;\n","[2023-10-11 09:28:29,853 INFO] Step 8400/10000; acc: 69.5; ppl:  11.8; xent: 2.5; lr: 0.00096; sents:   21898; bsz: 2690/3877/55; 17427/25115 tok/s;   5939 sec;\n","[2023-10-11 09:29:31,929 INFO] Step 8500/10000; acc: 69.7; ppl:  11.8; xent: 2.5; lr: 0.00096; sents:   23550; bsz: 2752/3918/59; 17734/25249 tok/s;   6002 sec;\n","[2023-10-11 09:30:34,222 INFO] Step 8600/10000; acc: 69.6; ppl:  11.8; xent: 2.5; lr: 0.00095; sents:   22949; bsz: 2775/3895/57; 17818/25009 tok/s;   6064 sec;\n","[2023-10-11 09:31:36,273 INFO] Step 8700/10000; acc: 69.7; ppl:  11.8; xent: 2.5; lr: 0.00095; sents:   23426; bsz: 2772/3914/59; 17873/25232 tok/s;   6126 sec;\n","[2023-10-11 09:32:38,262 INFO] Step 8800/10000; acc: 69.7; ppl:  11.7; xent: 2.5; lr: 0.00094; sents:   22358; bsz: 2745/3877/56; 17712/25017 tok/s;   6188 sec;\n","[2023-10-11 09:34:39,479 INFO] Step 8900/10000; acc: 70.1; ppl:  11.6; xent: 2.4; lr: 0.00094; sents:   23923; bsz: 2735/3913/60; 9027/12911 tok/s;   6309 sec;\n","[2023-10-11 09:35:41,001 INFO] Step 9000/10000; acc: 69.9; ppl:  11.6; xent: 2.5; lr: 0.00093; sents:   23251; bsz: 2738/3880/58; 17804/25230 tok/s;   6371 sec;\n","[2023-10-11 09:35:41,204 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 09:35:46,137 INFO] valid stats calculation\n","                           took: 5.132979154586792 s.\n","[2023-10-11 09:35:46,140 INFO] Train perplexity: 17.3875\n","[2023-10-11 09:35:46,140 INFO] Train accuracy: 61.9189\n","[2023-10-11 09:35:46,140 INFO] Sentences processed: 2.11251e+06\n","[2023-10-11 09:35:46,140 INFO] Average bsz: 2748/3894/59\n","[2023-10-11 09:35:46,140 INFO] Validation perplexity: 10.9771\n","[2023-10-11 09:35:46,140 INFO] Validation accuracy: 71.4623\n","[2023-10-11 09:35:46,140 INFO] Model is improving ppl: 11.3902 --> 10.9771.\n","[2023-10-11 09:35:46,141 INFO] Model is improving acc: 70.5202 --> 71.4623.\n","[2023-10-11 09:35:46,152 INFO] Saving checkpoint models/model.en-nl_step_9000.pt\n","[2023-10-11 09:37:57,672 INFO] Step 9100/10000; acc: 70.3; ppl:  11.5; xent: 2.4; lr: 0.00093; sents:   23743; bsz: 2771/3901/59; 8109/11419 tok/s;   6507 sec;\n","[2023-10-11 09:38:59,861 INFO] Step 9200/10000; acc: 70.2; ppl:  11.5; xent: 2.4; lr: 0.00092; sents:   23372; bsz: 2780/3909/58; 17880/25144 tok/s;   6569 sec;\n","[2023-10-11 09:40:01,340 INFO] Step 9300/10000; acc: 70.5; ppl:  11.4; xent: 2.4; lr: 0.00092; sents:   23952; bsz: 2731/3895/60; 17772/25339 tok/s;   6631 sec;\n","[2023-10-11 09:41:03,360 INFO] Step 9400/10000; acc: 70.5; ppl:  11.4; xent: 2.4; lr: 0.00091; sents:   23115; bsz: 2761/3907/58; 17809/25202 tok/s;   6693 sec;\n","[2023-10-11 09:42:05,117 INFO] Step 9500/10000; acc: 70.4; ppl:  11.4; xent: 2.4; lr: 0.00091; sents:   22316; bsz: 2712/3865/56; 17568/25033 tok/s;   6755 sec;\n","[2023-10-11 09:43:06,910 INFO] Step 9600/10000; acc: 70.7; ppl:  11.3; xent: 2.4; lr: 0.00090; sents:   23383; bsz: 2760/3919/58; 17869/25371 tok/s;   6816 sec;\n","[2023-10-11 09:44:08,900 INFO] Step 9700/10000; acc: 70.5; ppl:  11.4; xent: 2.4; lr: 0.00090; sents:   23201; bsz: 2768/3879/58; 17858/25033 tok/s;   6878 sec;\n","[2023-10-11 09:45:10,668 INFO] Step 9800/10000; acc: 71.0; ppl:  11.2; xent: 2.4; lr: 0.00089; sents:   24385; bsz: 2747/3891/61; 17787/25196 tok/s;   6940 sec;\n","[2023-10-11 09:46:12,592 INFO] Step 9900/10000; acc: 70.7; ppl:  11.3; xent: 2.4; lr: 0.00089; sents:   23030; bsz: 2738/3897/58; 17683/25176 tok/s;   7002 sec;\n","[2023-10-11 09:48:12,170 INFO] Step 10000/10000; acc: 71.1; ppl:  11.1; xent: 2.4; lr: 0.00088; sents:   24631; bsz: 2756/3905/62; 9220/13064 tok/s;   7122 sec;\n","[2023-10-11 09:48:12,461 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=23)\n","\n","[2023-10-11 09:48:17,005 INFO] valid stats calculation\n","                           took: 4.832394123077393 s.\n","[2023-10-11 09:48:17,007 INFO] Train perplexity: 16.6604\n","[2023-10-11 09:48:17,007 INFO] Train accuracy: 62.7853\n","[2023-10-11 09:48:17,007 INFO] Sentences processed: 2.34764e+06\n","[2023-10-11 09:48:17,007 INFO] Average bsz: 2748/3894/59\n","[2023-10-11 09:48:17,008 INFO] Validation perplexity: 10.5809\n","[2023-10-11 09:48:17,008 INFO] Validation accuracy: 72.2897\n","[2023-10-11 09:48:17,008 INFO] Model is improving ppl: 10.9771 --> 10.5809.\n","[2023-10-11 09:48:17,008 INFO] Model is improving acc: 71.4623 --> 72.2897.\n","[2023-10-11 09:48:17,015 INFO] Saving checkpoint models/model.en-nl_step_10000.pt\n"]}]},{"cell_type":"code","source":["# For error debugging try:\n","# !dmesg -T"],"metadata":{"id":"XUYAvE8ffK2k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eShpS01j-Jcp"},"source":["# Translation\n","\n","Translation Options:\n","* `-model` - specify the last model checkpoint name; try testing the quality of multiple checkpoints\n","* `-src` - the subworded test dataset, source file\n","* `-output` - give any file name to the new translation output file\n","* `-gpu` - GPU ID, usually 0 if you have one GPU. Otherwise, it will translate on CPU, which would be slower.\n","* `-min_length` - [optional] to avoid empty translations\n","* `-verbose` - [optional] if you want to print translations\n","\n","Refer to [OpenNMT-py translation options](https://opennmt.net/OpenNMT-py/options/translate.html) for more details."]},{"cell_type":"code","metadata":{"id":"MbQEGTj4TybH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"11901723-e7d4-46a7-ef87-c7a9ae554ae3","executionInfo":{"status":"ok","timestamp":1697018223296,"user_tz":-120,"elapsed":197773,"user":{"displayName":"","userId":""}}},"source":["# Translate the \"subworded\" source file of the test dataset\n","# Change the model name, if needed.\n","!onmt_translate -model /content/drive/MyDrive/nmt/models/model.en-nl_step_10000.pt -src /content/drive/MyDrive/nmt/Europarl.en-nl.en-filtered.en.subword.test -output en-nl.translated -gpu 0 -min_length 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 09:53:50.070770: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-11 09:53:52.690667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-10-11 09:53:55.884677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-11 09:53:55.885162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-11 09:53:55.885329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","[2023-10-11 09:53:56,821 INFO] Loading checkpoint from /content/drive/MyDrive/nmt/models/model.en-nl_step_10000.pt\n","[2023-10-11 09:53:58,757 INFO] Loading data into the model\n","[2023-10-11 09:56:59,629 INFO] PRED SCORE: -0.4246, PRED PPL: 1.53 NB SENTENCES: 2000\n"]}]},{"cell_type":"code","metadata":{"id":"XHYihrgfIrIO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"112d5a77-2ae1-4e25-93a9-7bca03ffb120","executionInfo":{"status":"ok","timestamp":1697018295350,"user_tz":-120,"elapsed":543,"user":{"displayName":"","userId":""}}},"source":["# Check the first 5 lines of the translation file\n","!head -n 5 en-nl.translated"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["â–In â–on s â–la at s te â– ja ar â–he b ben â–we â– vo or uit gang â– ge bo ek t â–bi j â–de â–opening â–van â–de â–Inter gouvernement ele â–Conf er ent ie .\n","â–M ij n he er â–de â–Vo or zi tter , â–in â–m ij n â–ho or zi tting â– op â– 1 3 â–j anu ari â– z al â– ik â– ze g gen â–da t â– er â– vo or â–he t â–e in de â–van â– dit â– ja ar â– vier â– ja ar â– ge en â–spe ci fi eke â– vo or wa a rden â– zi j n â– ge s te ld â– vo or â–de â– uit vo ering â–van â–de â–we t ge v ing . â–I k â– z ou â–gr a ag â– zi en â–da t â–de â–amend emen ten â– 1 0 , â– 5 , â– 1 0 , â– 1 0 , â– 1 5 , â– 1 0 , â– 5 0 , â– 1 0 , â– 5 0 , â– 1 0 , â– 1 5 â– ja ar â– z ou den â– zi j n â–go edge k eur d .\n","â–De â–Europe se â–Ra ad â– z al â– zi j n â–men ing â–g even â–over â–de ze â–a an passing en .\n","â–B 4 - 1 3 6 4 / 9 6 â–van â–me v r ou w â–Aelvoet â–en â–and eren , â–name ns â–de â–ELDR - F rac ti e , â–over â–de â–crisis â–in â–de â–Noord el ijk e â–All i anti e ;\n","â–M ij n he er â–de â–Vo or zi tter , â–na ar â–m ij n â–men ing â–mo et en â–de â–prior ite ite n â–van â–he t â–we rk pro gram ma â–van â–de â–Commiss ie â– vo or â– 2 0 0 2 â–on mid d ell ijk â–a and ach t â–word en â–best e ed â–a an â–de â– uit d aging en â–van â–de â–Europe se â–Uni e , â– zo we l â– op â–he t â– ge bi ed â–van â–de â–interne â–mark t â–al s â– op â–he t â– ge bi ed â–van â–de â–interne â–mark t â–en â–de â–eco no m ische â–en â–monet aire â–uni e , â– vo oral â– op â–he t â– ge bi ed â–van â–de â–b uite n land se â–a ang ele gen he den .\n"]}]},{"cell_type":"code","source":["!pip3 install -r MT-Preparation/requirements.txt"],"metadata":{"id":"UBKPVZL8LNhd","executionInfo":{"status":"ok","timestamp":1697018359222,"user_tz":-120,"elapsed":5786,"user":{"displayName":"","userId":""}},"outputId":"4211494f-885c-41c6-f9ef-cf6c4c2cb026","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 2)) (1.5.3)\n","Collecting sentencepiece (from -r MT-Preparation/requirements.txt (line 3))\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r MT-Preparation/requirements.txt (line 2)) (1.16.0)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","metadata":{"id":"zRsJm6UET2C_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6890dba-29e8-4f03-92d7-b7787b1ecba4","executionInfo":{"status":"ok","timestamp":1697018408474,"user_tz":-120,"elapsed":5103,"user":{"displayName":"","userId":""}}},"source":["# If needed install/update sentencepiece\n","!pip3 install --upgrade -q sentencepiece\n","\n","# Desubword the translation file\n","!python3 MT-Preparation/subwording/3-desubword.py target.model en-nl.translated"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done desubwording! Output: en-nl.translated.desubword\n"]}]},{"cell_type":"code","metadata":{"id":"ai4RhhGaKBp1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b73811e-9070-4d07-fe03-0a746821ca93","executionInfo":{"status":"ok","timestamp":1697018420502,"user_tz":-120,"elapsed":432,"user":{"displayName":"","userId":""}}},"source":["# Check the first 5 lines of the desubworded translation file\n","!head -n 5 en-nl.translated.desubword"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In ons laatste jaar hebben we vooruitgang geboekt bij de opening van de Intergouvernementeleâ–Conferentie.\n","Mijnheer de Voorzitter, in mijn hoorzitting op 13â–januari zal ik zeggen dat er voor hetâ–einde van dit jaar vier jaar geen specifieke voorwaarden zijn gesteld voor de uitvoering van de wetgeving. Ik zouâ–graag zien dat deâ–amendementen 10, 5, 10, 10, 15, 10, 50, 10, 50, 10, 15 jaar zouden zijn goedgekeurd.\n","De Europese Raad zal zijn mening geven over deze aanpassingen.\n","B4-1364/96 van mevrouw Aelvoet en anderen, namens de ELDR-Fractie, over de crisis in de Noordelijke Alliantie;\n","Mijnheer de Voorzitter, naar mijn mening moeten deâ–prioriteiten van het werkprogramma van de Commissie voor 2002 onmiddellijk aandacht worden besteed aan de uitdagingen van de Europese Unie, zowel op het gebied van de interne markt als op het gebied van de interne markt en de economische enâ–monetaireâ–unie, vooral op het gebied van de buitenlandse aangelegenheden.\n"]}]},{"cell_type":"code","metadata":{"id":"kOUWB4r3OFOV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"acc14dfe-f917-4a1c-d54a-bc945ca3de74","executionInfo":{"status":"ok","timestamp":1697018452855,"user_tz":-120,"elapsed":969,"user":{"displayName":"","userId":""}}},"source":["# Desubword the target file (reference) of the test dataset\n","# Note: You might as well have split files *before* subwording during dataset preperation,\n","# but sometimes datasets have tokeniztion issues, so this way you are sure the file is really untokenized.\n","!python3 MT-Preparation/subwording/3-desubword.py target.model /content/drive/MyDrive/nmt/Europarl.en-nl.nl-filtered.nl.subword.test"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done desubwording! Output: /content/drive/MyDrive/nmt/Europarl.en-nl.nl-filtered.nl.subword.test.desubword\n"]}]},{"cell_type":"code","metadata":{"id":"0jULN0MwOFeH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"db4298b1-2f8b-4704-e1d4-b658661d27d0","executionInfo":{"status":"ok","timestamp":1697018479787,"user_tz":-120,"elapsed":399,"user":{"displayName":"","userId":""}}},"source":["# Check the first 5 lines of the desubworded reference\n","!head -n 5 /content/drive/MyDrive/nmt/Europarl.en-nl.nl-filtered.nl.subword.test.desubword"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tijdens ons debat van vorig jaar verheugden we ons op de start van de Intergouvernementeleâ–Conferentie.\n","Mijnheer de Voorzitter, ik herinner me in mijn hoorzitting op 13â–januari precies te hebben gezegd dat ik er in de vijfâ–jaren die weâ–samen zouden doorbrengen,â–ernaar zouâ–streven omâ–samen met andere collega's, want ik benâ–niet de enigeâ–commissaris, er hebben waarschijnlijk vijftien ofâ–zestienâ–commissarissen te maken met een redelijk groot deel van de wetgeving, 1 500 teksten met elkaar te verenigen die moeten worden toegepast en intelligent moeten worden toegepast op de markt.\n","De Europese Raad zal zich vervolgens over deze aanpassingen uitspreken.\n","B4-1346/96 van mevrouw AndrÃ© en anderen, namens deâ–Fractie van de Europese Liberale enâ–Democratischeâ–Partij, over de crisis in Oost-ZaÃ¯re; -B4-1367/96 van mevrouw Baldi en anderen, namens deâ–Fractie Unie voor Europa, over de situatie in ZaÃ¯re; -B4-1392/96 van mevrouw Sauquillo PÃ©rezâ–del Arco en de heer Pons Grau, namens deâ–Fractie van deâ–Partij van de Europese Sociaal-democraten, over het vredesproces in Ruanda en ZaÃ¯re; -B4-1405/96 van de heer Carnero GonzÃ¡lez en anderen, namens de Confederaleâ–Fractie Europees Unitairâ–Links - Noordsâ–Groenâ–Links, over de situatie in het oosten van ZaÃ¯re; -B4-1417/96 van mevrouw GÃ¼nther en anderen, namens deâ–Fractie van de Europese Volkspartij, over de toestand in het oosten van ZaÃ¯re; -B4-1428/96 van mevrouw Aelvoet en de heer TelkÃ¤mper, namens deâ–Fractie Deâ–Groenen in het Europees Parlement, over de situatie in het oosten van ZaÃ¯re.\n","Mijnheer de Voorzitter, mijns inziens moeten deâ–prioriteiten van het werkprogramma van de Commissie voor het jaar 2002 zichâ–richten op de onmiddellijke uitdagingen die de Europese Unie te wachten staan, zowel vanuit intern oogpunt - de interne markt en deâ–Economische enâ–Monetaire Unie - als op het gebied van de buitenlandse betrekkingen - met name na de aanslagen van 11 september -, uiteraard met inbegrip van deâ–terrorismebestrijding.\n"]}]},{"cell_type":"markdown","metadata":{"id":"bHMumxqvLDDc"},"source":["# MT Evaluation\n","\n","There are several MT Evaluation metrics such as BLEU, TER, METEOR, COMET, BERTScore, among others.\n","\n","Here we are using BLEU. Files must be detokenized/desubworded beforehand."]},{"cell_type":"code","metadata":{"id":"w-9XGYnaJ-Nj","executionInfo":{"status":"ok","timestamp":1697018493750,"user_tz":-120,"elapsed":876,"user":{"displayName":"","userId":""}},"outputId":"ef0db49d-fc76-4d8c-a3e3-6616267e8cac","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Download the BLEU script\n","!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-11 10:01:31--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 957 [text/plain]\n","Saving to: â€˜compute-bleu.pyâ€™\n","\n","compute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n","\n","2023-10-11 10:01:31 (16.5 MB/s) - â€˜compute-bleu.pyâ€™ saved [957/957]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"rYDG0x0KLk_O","executionInfo":{"status":"ok","timestamp":1697018502406,"user_tz":-120,"elapsed":4863,"user":{"displayName":"","userId":""}},"outputId":"a4d10e7a-11e7-4506-acce-24ba9158dd43","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Install sacrebleu\n","!pip3 install sacrebleu"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.3.1)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n"]}]},{"cell_type":"code","metadata":{"id":"W3V3tZphTzK9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d92c1d15-6816-44b9-a6be-4f8b620a3308","executionInfo":{"status":"ok","timestamp":1697018553749,"user_tz":-120,"elapsed":1638,"user":{"displayName":"","userId":""}}},"source":["# Evaluate the translation (without subwording)\n","!python3 compute-bleu.py /content/drive/MyDrive/nmt/Europarl.en-nl.nl-filtered.nl.subword.test.desubword en-nl.translated.desubword"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reference 1st sentence: Tijdens ons debat van vorig jaar verheugden we ons op de start van de Intergouvernementeleâ–Conferentie.\n","MTed 1st sentence: In ons laatste jaar hebben we vooruitgang geboekt bij de opening van de Intergouvernementeleâ–Conferentie.\n","BLEU:  14.973550832214752\n"]}]},{"cell_type":"markdown","metadata":{"id":"IBi1PhRv4bX9"},"source":["# More Features and Directions to Explore\n","\n","Experiment with the following ideas:\n","* Icrease `train_steps` and see to what extent new checkpoints provide better translation, in terms of both BLEU and your human evaluation.\n","\n","* Check other MT Evaluation mentrics other than BLEU such as [TER](https://github.com/mjpost/sacrebleu#ter), [WER](https://blog.machinetranslation.io/compute-wer-score/), [METEOR](https://blog.machinetranslation.io/compute-bleu-score/#meteor), [COMET](https://github.com/Unbabel/COMET), and [BERTScore](https://github.com/Tiiiger/bert_score). What are the conceptual differences between them? Is there special cases for using a specific metric?\n","\n","* Continue training from the last model checkpoint using the `-train_from` option, only if the training stopped and you want to continue it. In this case, `train_steps` in the config file should be larger than the steps of the last checkpoint you train from.\n","```\n","!onmt_train -config config.yaml -train_from models/model.fren_step_3000.pt\n","```\n","\n","* **Ensemble Decoding:** During translation, instead of adding one model/checkpoint to the `-model` argument, add multiple checkpoints. For example, try the two last checkpoints. Does it improve quality of translation? Does it affect translation seepd?\n","\n","* **Averaging Models:** Try to average multiple models into one model using the [average_models.py](https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/bin/average_models.py) script, and see how this affects translation quality.\n","```\n","python3 average_models.py -models model_step_xxx.pt model_step_yyy.pt -output model_avg.pt\n","```\n","* **Release the model:** Try this command and see how it reduce the model size.\n","```\n","onmt_release_model --model \"model.pt\" --output \"model_released.pt\n","```\n","* **Use CTranslate2:** For efficient translation, consider using [CTranslate2](https://github.com/OpenNMT/CTranslate2), a fast inference engine. Check out an [example](https://gist.github.com/ymoslem/60e1d1dc44fe006f67e130b6ad703c4b).\n","\n","* **Work on low-resource languages:** Find out more details about [how to train NMT models for low-resource languages](https://blog.machinetranslation.io/low-resource-nmt/).\n","\n","* **Train a multilingual model:** Find out helpful notes about [training multilingual models](https://blog.machinetranslation.io/multilingual-nmt).\n","\n","* **Publish a demo:** Show off your work through a [simple demo with CTranslate2 and Streamlit](https://blog.machinetranslation.io/nmt-web-interface/).\n"]}]}